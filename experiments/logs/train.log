2025-11-23 22:42:01,378 | root | INFO | Logging initialized. Writing to: experiments\logs\train.log
2025-11-23 22:42:01,383 | train | INFO | Loaded config from: configs/main_cnn_template.yaml
2025-11-23 22:42:01,383 | train | INFO | Config content:
Config(path=WindowsPath('configs/main_cnn_template.yaml'), data={'seed': 42, 'dataset': {'name': 'RAFDB', 'root': 'data/processed', 'splits_dir': 'data/splits', 'image_size': 128, 'channels': 1, 'train_split': 'train.csv', 'val_split': 'val.csv', 'test_split': 'test.csv'}, 'preprocessing': {'normalize': {'mean': [0.5], 'std': [0.5]}, 'use_hist_equalization': False}, 'augmentation': {'horizontal_flip': True, 'rotation_deg': 15, 'translate': 0.1, 'brightness': 0.2, 'contrast': 0.2, 'saturation': 0.0, 'hue': 0.0, 'random_erasing': True, 'random_erasing_p': 0.5, 'random_erasing_scale': [0.02, 0.33], 'random_erasing_ratio': [0.3, 3.3]}, 'training': {'batch_size': 64, 'num_epochs': 150, 'num_workers': 4, 'pin_memory': True, 'early_stopping_patience': 15}, 'optimizer': {'name': 'adamw', 'lr': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9}, 'scheduler': {'name': 'cosine_annealing', 'T_max': 50, 'eta_min': 1e-05}, 'logging': {'log_dir': 'experiments/logs', 'checkpoint_dir': 'experiments/checkpoints', 'save_best_metric': 'val_macro_f1', 'tensorboard': True}})
2025-11-23 22:42:01,383 | src.utils.seed | INFO | Setting global seed to 42
2025-11-23 22:42:01,388 | src.utils.seed | INFO | PyTorch cuDNN set to deterministic mode
2025-11-23 22:42:01,388 | train | INFO | Seed set to 42
2025-11-23 22:42:01,388 | train | INFO | Using device: cuda
2025-11-23 22:42:02,500 | train | INFO | Computing class counts for training set...
2025-11-23 22:42:34,073 | train | INFO | Class counts: [4338, 6292, 4254, 2801, 3585, 383, 3467]
2025-11-23 22:42:34,078 | train | INFO | Class weights (inverse frequency): [0.8272410035133362, 0.5703387260437012, 0.8435757756233215, 1.281175136566162, 1.0009962320327759, 9.369638442993164, 1.0350652933120728]
2025-11-23 22:42:34,096 | train | INFO | Model built:
MainCNN(
  (features): Sequential(
    (0): ConvBlock(
      (conv1): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (pointwise): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ELU(alpha=1.0, inplace=True)
      (conv2): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act2): ELU(alpha=1.0, inplace=True)
      (res_proj): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout2d(p=0.25, inplace=False)
    )
    (1): ConvBlock(
      (conv1): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ELU(alpha=1.0, inplace=True)
      (conv2): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act2): ELU(alpha=1.0, inplace=True)
      (res_proj): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (attention): SEBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=64, out_features=4, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=4, out_features=64, bias=False)
          (3): Sigmoid()
        )
      )
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout2d(p=0.25, inplace=False)
    )
    (2): ConvBlock(
      (conv1): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
        (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ELU(alpha=1.0, inplace=True)
      (conv2): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act2): ELU(alpha=1.0, inplace=True)
      (res_proj): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (attention): SEBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=128, out_features=8, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=8, out_features=128, bias=False)
          (3): Sigmoid()
        )
      )
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout2d(p=0.25, inplace=False)
    )
    (3): ConvBlock(
      (conv1): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ELU(alpha=1.0, inplace=True)
      (conv2): DepthwiseSeparableConv2d(
        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act2): ELU(alpha=1.0, inplace=True)
      (res_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (attention): SEBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=256, out_features=16, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=16, out_features=256, bias=False)
          (3): Sigmoid()
        )
      )
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout2d(p=0.25, inplace=False)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (classifier): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=256, out_features=256, bias=True)
    (2): ELU(alpha=1.0, inplace=True)
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=256, out_features=7, bias=True)
  )
)
2025-11-23 22:42:34,096 | train | INFO | Using AdamW optimizer (lr=0.001, weight_decay=0.0001)
2025-11-23 22:42:34,097 | train | INFO | Using CosineAnnealingLR scheduler (T_max=50, eta_min=1e-05)
2025-11-23 22:42:34,100 | train | INFO | Starting training for 150 epochs. Early stopping patience = 15, best metric = val_macro_f1
2025-11-23 22:43:44,419 | train | INFO | Epoch 001/150 [70.3s] Train: loss=2.1548, acc=0.1588, macroF1=0.1479 | Val: loss=1.9363, acc=0.1523, macroF1=0.0946
2025-11-23 22:43:44,419 | train | INFO | New best model at epoch 1 (val_macro_f1=0.0946). Saving checkpoint to experiments\checkpoints\best_model.pt
2025-11-23 22:44:49,777 | train | INFO | Epoch 002/150 [65.3s] Train: loss=1.9981, acc=0.1580, macroF1=0.1484 | Val: loss=1.9353, acc=0.1748, macroF1=0.0794
2025-11-23 22:44:49,779 | train | INFO | No improvement in best metric for 1 epoch(s). Best so far: 0.0946 at epoch 1
2025-11-23 22:46:02,813 | train | INFO | Epoch 003/150 [73.0s] Train: loss=1.9619, acc=0.1621, macroF1=0.1522 | Val: loss=1.9574, acc=0.1090, macroF1=0.0891
2025-11-23 22:46:02,816 | train | INFO | No improvement in best metric for 2 epoch(s). Best so far: 0.0946 at epoch 1
2025-11-23 22:47:12,107 | train | INFO | Epoch 004/150 [69.3s] Train: loss=1.9466, acc=0.1652, macroF1=0.1527 | Val: loss=1.9253, acc=0.1887, macroF1=0.1329
2025-11-23 22:47:12,108 | train | INFO | New best model at epoch 4 (val_macro_f1=0.1329). Saving checkpoint to experiments\checkpoints\best_model.pt
